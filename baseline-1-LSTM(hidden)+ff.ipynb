{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-03T14:35:03.045309Z",
     "start_time": "2025-06-03T14:35:01.674547Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from joblib import load\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import create_data_loaders, train_model, test_model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyperparameters",
   "id": "5f490c2a2ea1698e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T14:35:03.145113Z",
     "start_time": "2025-06-03T14:35:03.143596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 10\n",
    "MIN_DELTA = 1e-4"
   ],
   "id": "8cd1749c7315c835",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Baseline-1: LSTM (hidden) + ff",
   "id": "7df5df0ad061e0db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T14:35:04.576501Z",
     "start_time": "2025-06-03T14:35:04.567984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DualLSTMModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 run_size = 20,\n",
    "                 incoming_run_size = 45,\n",
    "                 run_hidden_size = 128,\n",
    "                 incoming_run_hidden_size = 128,\n",
    "                 num_layers = 1,\n",
    "                 dropout = 0.2,\n",
    "                 ff_hidden_sizes=None,\n",
    "                 ff_output_size=49):\n",
    "        super().__init__()\n",
    "        self.run_size = run_size\n",
    "        self.incoming_run_size = incoming_run_size\n",
    "        self.run_hidden_size = run_hidden_size\n",
    "        self.incoming_run_hidden_size = incoming_run_hidden_size\n",
    "\n",
    "        if ff_hidden_sizes is None:\n",
    "            ff_hidden_sizes = [128, 64]\n",
    "        self.lstm_run = nn.LSTM(\n",
    "            input_size=run_size,\n",
    "            hidden_size=run_hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.lstm_incoming_run = nn.LSTM(\n",
    "            input_size=incoming_run_size,\n",
    "            hidden_size=incoming_run_hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        last_output_size = run_hidden_size + incoming_run_hidden_size\n",
    "        ff_layers = []\n",
    "        prev_hidden_size = last_output_size\n",
    "\n",
    "        for hidden_size in ff_hidden_sizes:\n",
    "            ff_layers.extend([\n",
    "                nn.Linear(prev_hidden_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_hidden_size = hidden_size\n",
    "\n",
    "        ff_layers.append(nn.Linear(prev_hidden_size, ff_output_size))\n",
    "        self.fead_forward = nn.Sequential(*ff_layers)\n",
    "\n",
    "    def forward(self, x1, x2, lengths1, lengths2):\n",
    "        if lengths1 is not None:\n",
    "            x1_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x1, lengths1.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            lstm1_out_packed, (h1_n, c1_n) = self.lstm_run(x1_packed)\n",
    "            out_run = h1_n[-1]\n",
    "        else:\n",
    "            lstm1_out, (h1_n, c1_n) = self.lstm_run(x1)\n",
    "            out_run = h1_n[-1]\n",
    "\n",
    "        if lengths2 is not None:\n",
    "            x2_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x2, lengths2.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            lstm2_out_packed, (h2_n, c2_n) = self.lstm_incoming_run(x2_packed)\n",
    "            out_incoming_run = h2_n[-1]\n",
    "        else:\n",
    "            lstm2_out, (h2_n, c2_n) = self.lstm_incoming_run(x2)\n",
    "            out_incoming_run = h2_n[-1]\n",
    "\n",
    "        return self.fead_forward(torch.concat([out_run, out_incoming_run], dim=1))"
   ],
   "id": "8ce1d568128dec49",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T14:16:28.311724Z",
     "start_time": "2025-06-03T14:16:27.694334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model summary\n",
    "from torchinfo import summary\n",
    "\n",
    "model = DualLSTMModel()\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=(\n",
    "        torch.randn(32, 755, 20),  # x1\n",
    "        torch.randn(32, 755, 45),  # x2\n",
    "        torch.full((32,), 700),    # lengths1\n",
    "        torch.full((32,), 700)     # lengths2\n",
    "    )\n",
    ")"
   ],
   "id": "34c914a485ff04ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DualLSTMModel                            [32, 49]                  --\n",
       "├─LSTM: 1-1                              [22400, 128]              76,800\n",
       "├─LSTM: 1-2                              [22400, 128]              89,600\n",
       "├─Sequential: 1-3                        [32, 49]                  --\n",
       "│    └─Linear: 2-1                       [32, 128]                 32,896\n",
       "│    └─ReLU: 2-2                         [32, 128]                 --\n",
       "│    └─Dropout: 2-3                      [32, 128]                 --\n",
       "│    └─Linear: 2-4                       [32, 64]                  8,256\n",
       "│    └─ReLU: 2-5                         [32, 64]                  --\n",
       "│    └─Dropout: 2-6                      [32, 64]                  --\n",
       "│    └─Linear: 2-7                       [32, 49]                  3,185\n",
       "==========================================================================================\n",
       "Total params: 210,737\n",
       "Trainable params: 210,737\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 477.10\n",
       "==========================================================================================\n",
       "Input size (MB): 6.28\n",
       "Forward/backward pass size (MB): 45.94\n",
       "Params size (MB): 0.84\n",
       "Estimated Total Size (MB): 53.06\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T14:35:09.176174Z",
     "start_time": "2025-06-03T14:35:08.323632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_matrices = load('./data/processed/run_matrices.joblib')\n",
    "incoming_run_matrices = load('./data/processed/incoming_run_matrices.joblib')\n",
    "metrology_matrix = load('./data/processed/metrology_matrix.joblib')\n",
    "\n",
    "X_run = torch.from_numpy(run_matrices).float()\n",
    "X_incoming_run = torch.from_numpy(incoming_run_matrices).float()\n",
    "y = torch.from_numpy(metrology_matrix).float()\n",
    "print(X_run.shape, X_incoming_run.shape, y.shape)"
   ],
   "id": "e8c74880e8937843",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4140, 755, 20]) torch.Size([4140, 755, 45]) torch.Size([4140, 49])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T14:41:45.468179Z",
     "start_time": "2025-06-03T14:35:09.645477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_1_model = DualLSTMModel(\n",
    "    run_hidden_size=128,\n",
    "    incoming_run_hidden_size=128,\n",
    "    num_layers=1,\n",
    "    dropout=0.2,\n",
    "    ff_hidden_sizes=[128, 64]\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(X_run, X_incoming_run, y, train_ratio=0.7, val_ratio=0.1, batch_size=BATCH_SIZE, standardize=True, random_state=RANDOM_STATE)\n",
    "\n",
    "train_losses, val_losses = train_model(baseline_1_model, train_loader, val_loader, num_epochs=1, learning_rate=LEARNING_RATE, patience=PATIENCE, min_delta=MIN_DELTA, model_save_path='baseline-1-best-model.pth')"
   ],
   "id": "4bdc68eb42714f4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expanded_mask: torch.Size([4140, 755, 1])\n",
      "standardized: torch.Size([4140, 755, 20])\n",
      "expanded_mask: torch.Size([4140, 755, 1])\n",
      "standardized: torch.Size([4140, 755, 45])\n",
      "Epoch 1/1\n",
      "Train Loss: 23.877116, Val Loss: 0.081266\n",
      "Learning Rate: 1.00e-03\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_2025/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T14:42:48.695357Z",
     "start_time": "2025-06-03T14:42:32.973534Z"
    }
   },
   "cell_type": "code",
   "source": "test_results = test_model(baseline_1_model, test_loader)",
   "id": "8f78278e084e071a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on 26 batches...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T14:43:07.508258Z",
     "start_time": "2025-06-03T14:43:07.505162Z"
    }
   },
   "cell_type": "code",
   "source": "print({k: test_results[k] for k in ['test_loss', 'mse', 'mae', 'r2_score']})",
   "id": "2eb7bb26afe3c07d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.08184193920057553, 'mse': 0.08184580504894257, 'mae': 0.21791943907737732, 'r2_score': -1.7126636505126953}\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
