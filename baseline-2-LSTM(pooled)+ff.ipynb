{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-31T15:38:54.463014Z",
     "start_time": "2025-05-31T15:38:52.829391Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from joblib import load\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import create_data_loaders, train_model, test_model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyperparameters",
   "id": "5f490c2a2ea1698e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:38:54.545117Z",
     "start_time": "2025-05-31T15:38:54.543627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 10\n",
    "MIN_DELTA = 1e-4"
   ],
   "id": "8cd1749c7315c835",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Baseline-2: LSTM (pooled) + ff",
   "id": "7df5df0ad061e0db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:39:14.715143Z",
     "start_time": "2025-05-31T15:39:14.707308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DualLSTMModel2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 run_size = 20,\n",
    "                 incoming_run_size = 45,\n",
    "                 run_hidden_size = 128,\n",
    "                 incoming_run_hidden_size = 128,\n",
    "                 num_layers = 1,\n",
    "                 dropout = 0.2,\n",
    "                 ff_hidden_sizes=None,\n",
    "                 ff_output_size=49):\n",
    "        super().__init__()\n",
    "        self.run_size = run_size\n",
    "        self.incoming_run_size = incoming_run_size\n",
    "        self.run_hidden_size = run_hidden_size\n",
    "        self.incoming_run_hidden_size = incoming_run_hidden_size\n",
    "\n",
    "        # self.flag = True\n",
    "\n",
    "        if ff_hidden_sizes is None:\n",
    "            ff_hidden_sizes = [128, 64]\n",
    "        self.lstm_run = nn.LSTM(\n",
    "            input_size=run_size,\n",
    "            hidden_size=run_hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.lstm_incoming_run = nn.LSTM(\n",
    "            input_size=incoming_run_size,\n",
    "            hidden_size=incoming_run_hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        last_output_size = run_hidden_size + incoming_run_hidden_size\n",
    "        ff_layers = []\n",
    "        prev_hidden_size = last_output_size\n",
    "\n",
    "        for hidden_size in ff_hidden_sizes:\n",
    "            ff_layers.extend([\n",
    "                nn.Linear(prev_hidden_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_hidden_size = hidden_size\n",
    "\n",
    "        ff_layers.append(nn.Linear(prev_hidden_size, ff_output_size))\n",
    "        self.fead_forward = nn.Sequential(*ff_layers)\n",
    "\n",
    "    def forward(self, x1, x2, lengths1, lengths2):\n",
    "        if lengths1 is not None:\n",
    "            x1_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x1, lengths1.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            lstm1_out_packed, (h1_n, c1_n) = self.lstm_run(x1_packed)\n",
    "            lstm1_out, _ = nn.utils.rnn.pad_packed_sequence(lstm1_out_packed, batch_first=True)\n",
    "            # if self.flag:\n",
    "            #     print(lstm1_out.shape)\n",
    "            #     print(lengths1.shape)\n",
    "            #     print(lstm1_out.sum(dim=1).shape)\n",
    "\n",
    "            lengths1 = lengths1.unsqueeze(1)\n",
    "            out_run = lstm1_out.sum(dim=1) / lengths1\n",
    "            # if self.flag:\n",
    "            #     print(out_run.shape)\n",
    "            #     self.flag = False\n",
    "        else:\n",
    "            lstm1_out, (h1_n, c1_n) = self.lstm_run(x1)\n",
    "            out_run = lstm1_out.mean(dim=1)\n",
    "\n",
    "        if lengths2 is not None:\n",
    "            x2_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x2, lengths2.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            lstm2_out_packed, (h2_n, c2_n) = self.lstm_incoming_run(x2_packed)\n",
    "            lstm2_out, _ = nn.utils.rnn.pad_packed_sequence(lstm2_out_packed, batch_first=True)\n",
    "            lengths2 = lengths2.unsqueeze(1)\n",
    "            out_incoming_run = lstm2_out.sum(dim=1) / lengths2\n",
    "        else:\n",
    "            lstm2_out, (h2_n, c2_n) = self.lstm_incoming_run(x2)\n",
    "            out_incoming_run = lstm2_out.mean(dim=1)\n",
    "\n",
    "        return self.fead_forward(torch.concat([out_run, out_incoming_run], dim=1))"
   ],
   "id": "8ce1d568128dec49",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:39:33.458225Z",
     "start_time": "2025-05-31T15:39:32.835935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model summary\n",
    "from torchinfo import summary\n",
    "\n",
    "model = DualLSTMModel2()\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=(\n",
    "        torch.randn(32, 755, 20),  # x1: batch_size=8, seq_len=10, feature_dim=20\n",
    "        torch.randn(32, 755, 45),  # x2\n",
    "        torch.full((32,), 700),    # lengths1\n",
    "        torch.full((32,), 700)     # lengths2\n",
    "    )\n",
    ")"
   ],
   "id": "34c914a485ff04ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 700, 128])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DualLSTMModel2                           [32, 49]                  --\n",
       "├─LSTM: 1-1                              [22400, 128]              76,800\n",
       "├─LSTM: 1-2                              [22400, 128]              89,600\n",
       "├─Sequential: 1-3                        [32, 49]                  --\n",
       "│    └─Linear: 2-1                       [32, 128]                 32,896\n",
       "│    └─ReLU: 2-2                         [32, 128]                 --\n",
       "│    └─Dropout: 2-3                      [32, 128]                 --\n",
       "│    └─Linear: 2-4                       [32, 64]                  8,256\n",
       "│    └─ReLU: 2-5                         [32, 64]                  --\n",
       "│    └─Dropout: 2-6                      [32, 64]                  --\n",
       "│    └─Linear: 2-7                       [32, 49]                  3,185\n",
       "==========================================================================================\n",
       "Total params: 210,737\n",
       "Trainable params: 210,737\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 477.10\n",
       "==========================================================================================\n",
       "Input size (MB): 6.28\n",
       "Forward/backward pass size (MB): 45.94\n",
       "Params size (MB): 0.84\n",
       "Estimated Total Size (MB): 53.06\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:40:24.651970Z",
     "start_time": "2025-05-31T15:40:23.822169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_matrices = load('run_matrices.joblib')\n",
    "incoming_run_matrices = load('incoming_run_matrices.joblib')\n",
    "metrology_matrix = load('metrology_matrix.joblib')\n",
    "\n",
    "X_run = torch.from_numpy(run_matrices).float()\n",
    "X_incoming_run = torch.from_numpy(incoming_run_matrices).float()\n",
    "y = torch.from_numpy(metrology_matrix).float()\n",
    "print(X_run.shape, X_incoming_run.shape, y.shape)"
   ],
   "id": "e8c74880e8937843",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4140, 755, 20]) torch.Size([4140, 755, 45]) torch.Size([4140, 49])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:48:07.956756Z",
     "start_time": "2025-05-31T15:41:18.290349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_2_model = DualLSTMModel2(\n",
    "    run_hidden_size=128,\n",
    "    incoming_run_hidden_size=128,\n",
    "    num_layers=1,\n",
    "    dropout=0.2,\n",
    "    ff_hidden_sizes=[128, 64]\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(X_run, X_incoming_run, y, train_ratio=0.7, val_ratio=0.1, batch_size=BATCH_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "train_losses, val_losses = train_model(baseline_2_model, train_loader, val_loader, num_epochs=1, learning_rate=LEARNING_RATE, patience=PATIENCE, min_delta=MIN_DELTA, model_save_path='baseline-2-best-model.pth')"
   ],
   "id": "4bdc68eb42714f4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 729, 128])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "Epoch 1/1\n",
      "Train Loss: 28.093435, Val Loss: 0.100016\n",
      "Learning Rate: 1.00e-03\n",
      "--------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:48:22.119098Z",
     "start_time": "2025-05-31T15:48:08.001391Z"
    }
   },
   "cell_type": "code",
   "source": "test_results = test_model(baseline_2_model, test_loader)",
   "id": "8f78278e084e071a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on 26 batches...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:48:22.132395Z",
     "start_time": "2025-05-31T15:48:22.130119Z"
    }
   },
   "cell_type": "code",
   "source": "print({k: test_results[k] for k in ['test_loss', 'mse', 'mae', 'r2_score']})",
   "id": "2eb7bb26afe3c07d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.10404751808024369, 'mse': 0.10392114520072937, 'mae': 0.2574879825115204, 'r2_score': -2.444319486618042}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "93629b51e882c5fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
