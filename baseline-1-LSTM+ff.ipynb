{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-30T08:24:04.296825Z",
     "start_time": "2025-05-30T08:24:04.286852Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from joblib import load\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyperparameters",
   "id": "5f490c2a2ea1698e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T15:01:42.509622Z",
     "start_time": "2025-05-30T15:01:42.504834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 10\n",
    "MIN_DELTA = 1e-4"
   ],
   "id": "8cd1749c7315c835",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Models",
   "id": "62ce468e0daa66a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Baseline-1: LSTM + ff",
   "id": "7df5df0ad061e0db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class DualLSTMModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 run_size = 20,\n",
    "                 incoming_run_size = 45,\n",
    "                 run_hidden_size = 128,\n",
    "                 incoming_run_hidden_size = 128,\n",
    "                 num_layers = 1,\n",
    "                 dropout = 0.2,\n",
    "                 ff_hidden_sizes=None,\n",
    "                 ff_output_size=49):\n",
    "        super().__init__()\n",
    "        self.run_size = run_size\n",
    "        self.incoming_run_size = incoming_run_size\n",
    "        self.run_hidden_size = run_hidden_size\n",
    "        self.incoming_run_hidden_size = incoming_run_hidden_size\n",
    "\n",
    "        if ff_hidden_sizes is None:\n",
    "            ff_hidden_sizes = [256, 128]\n",
    "        self.lstm_run = nn.LSTM(\n",
    "            input_size=run_size,\n",
    "            hidden_size=run_hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.lstm_incoming_run = nn.LSTM(\n",
    "            input_size=incoming_run_size,\n",
    "            hidden_size=incoming_run_hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        last_output_size = run_hidden_size + incoming_run_hidden_size\n",
    "        ff_layers = []\n",
    "        prev_hidden_size = last_output_size\n",
    "\n",
    "        for hidden_size in ff_hidden_sizes:\n",
    "            ff_layers.extend([\n",
    "                nn.Linear(prev_hidden_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_hidden_size = hidden_size\n",
    "\n",
    "        ff_layers.append(nn.Linear(prev_hidden_size, ff_output_size))\n",
    "        self.fead_forward = nn.Sequential(*ff_layers)\n",
    "\n",
    "    def forward(self, x1, x2, lengths1, lengths2):\n",
    "        if lengths1 is not None:\n",
    "            x1_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x1, lengths1.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            lstm1_out_packed, (h1_n, c1_n) = self.lstm_run(x1_packed)\n",
    "            out_run = h1_n[-1]\n",
    "        else:\n",
    "            lstm1_out, (h1_n, c1_n) = self.lstm_run(x1)\n",
    "            out_run = h1_n[-1]\n",
    "\n",
    "        if lengths2 is not None:\n",
    "            x2_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x2, lengths2.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            lstm2_out_packed, (h2_n, c2_n) = self.lstm_incoming_run(x2_packed)\n",
    "            out_incoming_run = h2_n[-1]\n",
    "        else:\n",
    "            lstm2_out, (h2_n, c2_n) = self.lstm_incoming_run(x2)\n",
    "            out_incoming_run = h2_n[-1]\n",
    "\n",
    "        return self.fead_forward(torch.concat([out_run, out_incoming_run], dim=1))"
   ],
   "id": "8ce1d568128dec49",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:31:05.622329Z",
     "start_time": "2025-05-31T09:31:04.806765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model summary\n",
    "from torchinfo import summary\n",
    "\n",
    "model = DualLSTMModel()\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=(\n",
    "        torch.randn(32, 755, 20),  # x1: batch_size=8, seq_len=10, feature_dim=20\n",
    "        torch.randn(32, 755, 45),  # x2\n",
    "        torch.full((32,), 700),    # lengths1\n",
    "        torch.full((32,), 700)     # lengths2\n",
    "    )\n",
    ")"
   ],
   "id": "34c914a485ff04ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DualLSTMModel                            [32, 49]                  --\n",
       "├─LSTM: 1-1                              [22400, 128]              76,800\n",
       "├─LSTM: 1-2                              [22400, 128]              89,600\n",
       "├─Sequential: 1-3                        [32, 49]                  --\n",
       "│    └─Linear: 2-1                       [32, 256]                 65,792\n",
       "│    └─ReLU: 2-2                         [32, 256]                 --\n",
       "│    └─Dropout: 2-3                      [32, 256]                 --\n",
       "│    └─Linear: 2-4                       [32, 128]                 32,896\n",
       "│    └─ReLU: 2-5                         [32, 128]                 --\n",
       "│    └─Dropout: 2-6                      [32, 128]                 --\n",
       "│    └─Linear: 2-7                       [32, 49]                  6,321\n",
       "==========================================================================================\n",
       "Total params: 271,409\n",
       "Trainable params: 271,409\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 477.11\n",
       "==========================================================================================\n",
       "Input size (MB): 6.28\n",
       "Forward/backward pass size (MB): 45.99\n",
       "Params size (MB): 1.09\n",
       "Estimated Total Size (MB): 53.35\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 127,
   "source": [
    "def get_sequence_lengths(x, padding_value=0.0):\n",
    "    mask = (x != padding_value).any(dim=-1)\n",
    "    reversed_mask = torch.flip(mask, dims=[1])\n",
    "    lengths = mask.size(1) - reversed_mask.int().argmax(dim=1)\n",
    "    return lengths.to(dtype=torch.long, device=x.device)\n",
    "\n",
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x1, x2, y, padding_value=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x1: (4140, 755, 20) tensor\n",
    "            x2: (4140, 755, 45) tensor\n",
    "            y: (4140, 49) tensor\n",
    "            padding_value: Value used for padding (default: 0.0)\n",
    "        \"\"\"\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.y = y\n",
    "        self.padding_value = padding_value\n",
    "        assert len(x1) == len(x2) == len(y), \"All inputs must have the same number of samples!\"\n",
    "        self.lengths1 = get_sequence_lengths(x1, padding_value)\n",
    "        self.lengths2 = get_sequence_lengths(x2, padding_value)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x1)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return (\n",
    "            self.x1[item],\n",
    "            self.x2[item],\n",
    "            self.y[item],\n",
    "            self.lengths1[item],\n",
    "            self.lengths2[item]\n",
    "        )\n",
    "\n",
    "def create_data_loaders(x1, x2, y, train_ratio=0.8, val_ratio=0.1, batch_size = BATCH_SIZE, shuffle=False, num_workers=0, padding_value=0.0, random_state=RANDOM_STATE):\n",
    "    dataset = TimeSeriesDataset(x1, x2, y, padding_value)\n",
    "\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(train_ratio * total_size)\n",
    "    val_size = int(val_ratio * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(random_state)\n",
    "    )\n",
    "\n",
    "    loader_kwargs = dict(batch_size=batch_size, num_workers=num_workers, pin_memory=True) # TODO: Try pin_memory=False\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=shuffle, **loader_kwargs)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, shuffle=False, **loader_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, **loader_kwargs)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        x1, x2, y, lengths1, lengths2 = batch_data\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        lengths1, lengths2 = lengths1.to(device), lengths2.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x1, x2, lengths1, lengths2)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # TODO: See if need this\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in val_loader:\n",
    "            x1, x2, y, lengths1, lengths2 = batch_data\n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "            lengths1, lengths2 = lengths1.to(device), lengths2.to(device)\n",
    "\n",
    "            outputs = model(x1, x2, lengths1, lengths2)\n",
    "            loss = criterion(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE, device='cuda' if torch.cuda.is_available() else 'cpu', patience=PATIENCE, min_delta=MIN_DELTA):\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # TODO: Try AdamW, try weight_decay=1e-5\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    ) # TODO: Try different hyperparameters\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate_epoch(model, val_loader, criterion, device)\n",
    "        lr_scheduler.step(val_loss)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Printing\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model weights\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def test_model(model, test_loader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_losses = []\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    print(f\"Testing model on {len(test_loader)} batches...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            x1, x2, y, lengths1, lengths2 = batch_data\n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "            lengths1, lengths2 = lengths1.to(device), lengths2.to(device)\n",
    "\n",
    "            outputs = model(x1, x2, lengths1, lengths2)\n",
    "            loss = criterion(outputs, y)\n",
    "            all_losses.append(loss.item())\n",
    "            all_predictions.append(outputs.cpu())\n",
    "            all_targets.append(y.cpu())\n",
    "\n",
    "    test_loss = sum(all_losses) / len(all_losses)\n",
    "\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    results = {\n",
    "        'test_loss': test_loss,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets\n",
    "    }\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = torch.nn.functional.mse_loss(all_predictions, all_targets).item()\n",
    "    mae = torch.nn.functional.l1_loss(all_predictions, all_targets).item()\n",
    "\n",
    "    # R^2 score (coefficient of determination)\n",
    "    ss_res = torch.sum((all_targets - all_predictions) ** 2)\n",
    "    ss_tot = torch.sum((all_targets - torch.mean(all_targets)) ** 2)\n",
    "    r2_score = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    rmse = torch.sqrt(torch.tensor(mse)).item()\n",
    "\n",
    "    results.update({\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2_score': r2_score.item()\n",
    "    })\n",
    "\n",
    "    return results"
   ],
   "id": "31032330ab29d4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T16:18:34.725909Z",
     "start_time": "2025-05-30T16:18:34.321971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_matrices = load('run_matrices.joblib')\n",
    "incoming_run_matrices = load('incoming_run_matrices.joblib')\n",
    "metrology_matrix = load('metrology_matrix.joblib')\n",
    "\n",
    "X_run = torch.from_numpy(run_matrices).float()\n",
    "X_incoming_run = torch.from_numpy(incoming_run_matrices).float()\n",
    "y = torch.from_numpy(metrology_matrix).float()\n",
    "print(X_run.shape, X_incoming_run.shape, y.shape)"
   ],
   "id": "e8c74880e8937843",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4140, 755, 20]) torch.Size([4140, 755, 45]) torch.Size([4140, 49])\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T16:25:06.015594Z",
     "start_time": "2025-05-30T16:18:43.560698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_1_model = DualLSTMModel(\n",
    "    run_hidden_size=128,\n",
    "    incoming_run_hidden_size=128,\n",
    "    num_layers=1,\n",
    "    dropout=0.2,\n",
    "    ff_hidden_sizes=[256, 128]\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(X_run, X_incoming_run, y, train_ratio=0.7, val_ratio=0.1)\n",
    "\n",
    "train_losses, val_losses = train_model(baseline_1_model, train_loader, val_loader, num_epochs=1)"
   ],
   "id": "4bdc68eb42714f4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Train Loss: 20.260741, Val Loss: 0.075996\n",
      "Learning Rate: 1.00e-03\n",
      "--------------------\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T16:25:30.725488Z",
     "start_time": "2025-05-30T16:25:17.566749Z"
    }
   },
   "cell_type": "code",
   "source": "test_results = test_model(baseline_1_model, test_loader)",
   "id": "8f78278e084e071a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on 26 batches...\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T16:28:45.792249Z",
     "start_time": "2025-05-30T16:28:45.790293Z"
    }
   },
   "cell_type": "code",
   "source": "print({k: test_results[k] for k in ['test_loss', 'mse', 'mae', 'r2_score']})",
   "id": "2eb7bb26afe3c07d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.12389485280101116, 'mse': 0.12407800555229187, 'mae': 0.22869639098644257, 'r2_score': -3.1123900413513184}\n"
     ]
    }
   ],
   "execution_count": 137
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
